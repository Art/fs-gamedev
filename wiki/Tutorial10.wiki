#summary Parsing DirectX' .X files.

== Introduction ==

This tutorial shows how to parse .X files, which are used for 3d models and scenes. Note that DirectX offers convenient functions to manipulate these files.

Be aware that the code in this tutorial is not fully functional. Some of its limitations include poor error reporting and producing a raw representation of the content of the file which is not easily directly usable.

Nevertheless, writing this code was an educational experience, and programmers writing games on platforms where DirectX is not available may find this code useful.

=== The .X format ===

A fairly comprehensive description of the file format is available on MSDN or on http://ozviz.wasp.uwa.edu.au/~pbourke/dataformats/directx/.

An .X file can basically divided into two parts. The first declares data structures, the second defines data, which structured according to the declarations in the first part.

=== Parser Architecture ===

There are several options for the design of the parser:
  # Ignore the data structures declared in the first part, and assume they match the standard definitions by Microsoft; then parse the second part using a "hard-wired" data parser.
  # Parse the data structure declarations, producing data which is used when parsing the second part.
  # Parse the data structure declarations, producing parsers which are used to parse the second part.

I find the third option to be the most attractive, mostly for aesthetic reasons. It is therefore the one used for the code of this tutorial.

== Code ==

The full code is available at http://code.google.com/p/fs-gamedev/source/browse/#svn/trunk/Tutorial013.

It is organized into the following modules:
  * *XLexers.fs* The interface of lexers, i.e. functions turning bytes read from a file into data sent to the parser.
  * *TextLexer.fs* An implementation of a lexer which extracts data from text files. .X files may also be binary files, but this case is not handled in this tutorial. *TextLexer.fs* is automatically generated by fslex from *TextLexer.fsl*.
  * *XParsers.fs* The parser.
  * *Program.fs* Entry point for the application.

=== XLexers.fs ===

{{{
type Token =
    | NAME of string
    | STRING of string 
    | INTEGER of int
    | FLOATVAL of float
    | UUID of string
    | INTEGER_LIST of int list   // Not used ?!
    | FLOAT_LIST of float list   // Not used ?!
    | OBRACE | CBRACE | OPAREN | CPAREN
    | OBRACKET | CBRACKET | OANGLE | CANGLE
    | DOT | COMMA | SEMICOLON
    | TEMPLATE
    | WORD | DWORD
    | FLOAT | DOUBLE
    | CHAR | UCHAR
    | SWORD | SDWORD
    | VOID
    | LPSTR
    | UNICODE
    | CSTRING
    | NSTRING
    | ARRAY
    | EOF

}}}

This defines a _discriminated union_. A variable of type `Token` can be a `NAME`, in which case its value is a `string`, or a `INTEGER`, in which case its value is an `int`, and so on...

`NAME` and `INTEGER` are called _discriminators_, and are used to identify the actual type of a variable of type `Token`.

{{{
type Lexer<'Src> = 'Src -> (Token * 'Src) option
}}}

Another type definition: This is the signature of functions turning file contents into tokens. The type `Lexer` is parametrized by the type of the source from which tokens are extracted. A `Lexer` takes a source, and returns:
  * a pair of a token and a new source, or
  * nothing, if there was an error while reading the source, or if the source is ill-formatted.

Typically, the source contains information about the file being read, and where the 'head' points inside the file.
The lexer is expected to return a the source it was passed, with the difference that the position is updated to point after the token that was just read.

{{{
let expect nextToken (src : 'Src) (tokens : Token list) =
    let rec work src tokens =
        match tokens with
        | [] -> Some src
        | tok :: toks ->
            match nextToken src with
            | Some(head, rest) when head = tok -> work rest toks
            | _ -> None
    work src tokens
}}}

The function `expect` takes a lexer (somewhat misleadingly called `nextToken`), a source and a list of expected tokens. It checks that the sequence of tokens extracted from the source matches the expected list, then returns the source, pointing after the sequence of tokens. If the lexer returned a token which was not expected, or reached the end of the source too early, `None` is returned.

{{{
let maybeExpect nextToken (tokens : Token list) (in_data : ('a * 'Src) option) =
    match in_data with
    | Some(smthing, src) ->
        match expect nextToken src tokens with
        | Some(src) -> Some(smthing, src)
        | None -> None
    | None -> None
}}}

This is a convenience function. It does the same as `expect`, with the addition that it takes some data `in_data`, composed of any kind of data `'a` and a source.
It returns the `'a` data and the updated source if `expect` succeeds, or None otherwise.
This function somewhat helps to improve the readability of the code of XParser.fs.

TBC...
== Conclusion ==